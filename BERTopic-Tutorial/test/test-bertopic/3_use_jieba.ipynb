{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理中文，并使用jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"今天的天气晴朗，天空湛蓝。\",\n",
    "    \"明天的预报预测将有大雨和雷暴。\",\n",
    "    \"我喜欢在温和的天气下观看日落。\",\n",
    "    \"自然语言处理是计算机科学的一个研究领域。\",\n",
    "    \"NLP技术被广泛用于文本分析和语言理解。\",\n",
    "    \"天气预报依赖于复杂的算法和数据分析。\",\n",
    "    \"了解天气模式对农业和灾害管理至关重要。\",\n",
    "    \"NLP算法可以帮助分析社交媒体帖子的情感。\",\n",
    "    \"天气可能会变化无常，尤其是在季节交替时。\",\n",
    "    \"像BERT和GPT-3这样的NLP模型已经彻底改变了语言理解任务。\",\n",
    "    \"极端天气事件如飓风和龙卷风需要先进的预测模型。\",\n",
    "    \"NLP被用于像Siri和Alexa这样的虚拟助手，以理解人类命令。\",\n",
    "    \"气候变化正在影响全球的天气模式。\",\n",
    "    \"NLP可以帮助进行机器翻译，使跨语言交流变得更容易。\",\n",
    "    \"气象卫星提供实时数据供气象学家分析。\",\n",
    "    \"语义分析是自然语言处理的重要组成部分。\",\n",
    "    \"天气现象如厄尔尼诺影响着全球的天气。\",\n",
    "    \"词性标注是NLP中的一个基本任务。\",\n",
    "    \"沿海地区的天气常受海洋洋流影响。\",\n",
    "    \"NLP有助于聊天机器人生成类似人类的回复。\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://maartengr.github.io/BERTopic/api/bertopic.html\n",
    "The default embedding model is all-MiniLM-L6-v2 when selecting language=\"english\" and paraphrase-multilingual-MiniLM-L12-v2 when selecting language=\"multilingual\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用能处理中文的词嵌入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用jieba分词\n",
    "https://maartengr.github.io/BERTopic/faq.html#how-can-i-use-bertopic-with-chinese-documents\n",
    "How can I use BERTopic with Chinese documents?\n",
    "Currently, CountVectorizer tokenizes text by splitting whitespace which does not work for Chinese. To get it to work, you will have to create a custom CountVectorizer with jieba:\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "\n",
    "def tokenize_zh(text):\n",
    "    words = jieba.lcut(text)\n",
    "    return words\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_zh(text):\n",
    "    words = jieba.lcut(text) # 切词，并返回list\n",
    "    print('切词：', words)\n",
    "    return words\n",
    "\n",
    "vectorizer_model = CountVectorizer(tokenizer=tokenize_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里有两个问题\n",
    "# 其一是每次运行模型都会执行切词操作，非常浪费时间\n",
    "# 其二是介词会包含：标点符号、的、了等虚词，这些词更应该被排除在外\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  vectorizer_model=vectorizer_model,\n",
    ")\n",
    "\n",
    "topic_model.fit_transform(sentences) # 训练模型\n",
    "topic_model.get_topic_info() # 获取主题聚类信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_docs = topic_model.get_document_info(sentences)\n",
    "topic_docs.to_csv('./聚类结果.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
